{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0873a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "# For LSTM model\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "# For hyperopt (parameter optimization)\n",
    "from hyperopt import Trials, STATUS_OK, tpe, fmin, hp\n",
    "from hyperopt.pyll.base import scope  # quniform returns float, some parameters require int; use this to force int\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(data, weeks=1):\n",
    "    X_total = data.values[:209, :]\n",
    "\n",
    "    data = X_total[(53-weeks):, :]\n",
    "    print(data.shape)\n",
    "    scaler, values = utils.scale(data)\n",
    "    values = utils.series_to_supervised(values, n_in=weeks, n_out=1, dropnan=True).values\n",
    "\n",
    "    y_scaler, y = utils.scale(data[:, 1].reshape((len(data), 1)))\n",
    "\n",
    "    train = values[:140, :]\n",
    "    valid = values[140:148]\n",
    "    test = values[148:, :]\n",
    "    print(train.shape, valid.shape, test.shape)\n",
    "\n",
    "    features = 13\n",
    "    obs = weeks*features\n",
    "\n",
    "    y = values[:, -features:]\n",
    "\n",
    "    trainX = train[:, :obs]\n",
    "    trainY = train[:, -features:][:, 1]\n",
    "    validX = valid[:, :obs]\n",
    "    validY = valid[:, -features:][:, 1]\n",
    "    testX = test[:, :obs]\n",
    "    testY = test[:, -features:][:, 1]\n",
    "\n",
    "    trainX = trainX.reshape((trainX.shape[0], weeks, features))\n",
    "    validX = validX.reshape((validX.shape[0], weeks, features))\n",
    "    testX = testX.reshape((testX.shape[0], weeks, features))\n",
    "\n",
    "    return trainX, trainY, validX, validY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478515fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_scale_data(data, weeks=1):\n",
    "    X_total = data.values[:209, :]\n",
    "\n",
    "    data = X_total[(53-weeks):, :]\n",
    "    print(data.shape)\n",
    "    scaler, values = utils.scale(data)\n",
    "    values = utils.series_to_supervised(values, n_in=weeks, n_out=1, dropnan=True).values\n",
    "\n",
    "    y_scaler, y = utils.scale(data[:, 1].reshape((len(data), 1)))\n",
    "\n",
    "    train = values[:140, :]\n",
    "    valid = values[140:148]\n",
    "    test = values[148:, :]\n",
    "    print(train.shape, valid.shape, test.shape)\n",
    "\n",
    "    features = 13\n",
    "    obs = weeks*features\n",
    "\n",
    "    y = values[:, -features:]\n",
    "\n",
    "    trainX = train[:, :obs]\n",
    "    trainY = train[:, -features:][:, 1]\n",
    "    validX = valid[:, :obs]\n",
    "    validY = valid[:, -features:][:, 1]\n",
    "    testX = test[:, :obs]\n",
    "    testY = test[:, -features:][:, 1]\n",
    "\n",
    "    trainX = trainX.reshape((trainX.shape[0], weeks, features))\n",
    "    validX = validX.reshape((validX.shape[0], weeks, features))\n",
    "    testX = testX.reshape((testX.shape[0], weeks, features))\n",
    "\n",
    "    return trainX, trainY, validX, validY, testX, testY, scaler, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06371330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    def f_nn(params):\n",
    "        # Generate data with given window\n",
    "        saltlake_week = pd.read_csv('../saltlake_week.csv')\n",
    "        data = saltlake_week[['Cases', 'VMT (Veh-Miles)', 'News Sentiment', 'Unemployment Rate', 'PRCP', 'SNWD',\n",
    "                              'Percent_Fully_Vaccinated_5&Older', 'TAVG',\n",
    "                              'Stay at Home', 'Mask', 'School Opening', 'Health Emergency', 'Holiday']]\n",
    "        trainX, trainY, validX, validY, testX, testY = format_data(data=data, weeks=params['weeks'])\n",
    "        \n",
    "        # Keras LSTM model\n",
    "        model = Sequential()\n",
    "\n",
    "        if params['layers'] == 1:\n",
    "            model.add(LSTM(units=params['units'], input_shape=(trainX.shape[1], trainX.shape[2]),\n",
    "                           activation=params['activation']))                \n",
    "            model.add(Dropout(rate=params['dropout']))\n",
    "        else:\n",
    "            # First layer specifies input_shape and returns sequences\n",
    "            model.add(\n",
    "                LSTM(units=params['units'], return_sequences=True, input_shape=(trainX.shape[1], trainX.shape[2]),\n",
    "                        activation=params['activation']))\n",
    "            model.add(Dropout(rate=params['dropout']))\n",
    "            # Middle layers return sequences\n",
    "            for i in range(params['layers'] - 2):\n",
    "                model.add(LSTM(units=params['units'], return_sequences=True, activation=params['activation']))\n",
    "                model.add(Dropout(rate=params['dropout']))\n",
    "            # Last layer doesn't return anything\n",
    "            model.add(LSTM(units=params['units'], activation=params['activation']))\n",
    "            model.add(Dropout(rate=params['dropout']))\n",
    "\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "\n",
    "        result = model.fit(trainX, trainY, verbose=0, validation_data=(validX, validY),\n",
    "                            batch_size=4,\n",
    "                            epochs=200,\n",
    "                            callbacks=[es, TqdmCallback(verbose=1)]\n",
    "                            )\n",
    "\n",
    "        # get the lowest validation loss of the training epochs\n",
    "        validation_loss = np.amin(result.history['val_loss'])\n",
    "        print('Best validation loss of epoch:', validation_loss)\n",
    "\n",
    "\n",
    "        return {'loss': validation_loss, 'status': STATUS_OK, 'model': model, 'params': params}\n",
    "\n",
    "    # hyperparameters to search over with hyperopt\n",
    "    space = {'dropout': hp.uniform('dropout', 0.01, 0.5),\n",
    "             'units': scope.int(hp.quniform('units', 8, 128, 4)),\n",
    "             'layers': scope.int(hp.quniform('layers', 1, 6, 1)),\n",
    "             'weeks': scope.int(hp.quniform('weeks', 1, 10, 1)),\n",
    "             'activation': hp.choice('activation', ['relu', 'sigmoid', 'tanh'])\n",
    "             }\n",
    "\n",
    "    trials = Trials()\n",
    "    best = fmin(f_nn, space, algo=tpe.suggest, max_evals=200, trials=trials)\n",
    "\n",
    "    # get best model\n",
    "    best_model = trials.results[np.argmin([r['loss'] for r in trials.results])]['model']\n",
    "    best_params = trials.results[np.argmin([r['loss'] for r in trials.results])]['params']\n",
    "\n",
    "    print(best_params)\n",
    "    print(best_model.summary())\n",
    "    best_model.save('Model/LSTM-3')\n",
    "    \n",
    "    saltlake_week = pd.read_csv('../saltlake_week.csv')\n",
    "    data = saltlake_week[['Cases', 'VMT (Veh-Miles)', 'News Sentiment', 'Unemployment Rate', 'PRCP', 'SNWD',\n",
    "                          'Percent_Fully_Vaccinated_5&Older', 'TAVG', \n",
    "                          'Stay at Home', 'Mask', 'School Opening', 'Health Emergency', 'Holiday']]\n",
    "    trainX, trainY, validX, validY, testX, testY, scaler, y_scaler = format_scale_data(data=data, weeks=best_params['weeks'])\n",
    "    \n",
    "    best_model.evaluate(testX, testY)\n",
    "    \n",
    "    yhat_test = best_model.predict(testX)\n",
    "    yhat_test_inv = y_scaler.inverse_transform(yhat_test).reshape((-1, 1))\n",
    "    testY_inv = y_scaler.inverse_transform(testY.reshape((-1, 1)))\n",
    "    \n",
    "    yhat_train = best_model.predict(trainX).reshape((-1, 1))\n",
    "    yhat_train_inv = y_scaler.inverse_transform(yhat_train)\n",
    "    trainY_inv = y_scaler.inverse_transform(trainY.reshape((-1, 1)))\n",
    "    \n",
    "    print(\"Mean Squared Error: {}\".format(mean_squared_error(testY_inv, yhat_test_inv)))\n",
    "    print(\"Root Mean Squared Error: {}\".format(mean_squared_error(testY_inv, yhat_test_inv, squared=False)))\n",
    "    print(\"Mean Absolute Percentage Error: {}\".format(mean_absolute_percentage_error(testY_inv, yhat_test_inv)))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(yhat_test_inv, label='Predicted')\n",
    "    plt.plot(testY_inv, label='True')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(yhat_train_inv, label='Predicted')\n",
    "    plt.plot(trainY_inv, label='True')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
