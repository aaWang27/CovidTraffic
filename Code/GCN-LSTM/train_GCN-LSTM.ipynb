{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5865879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import utils\n",
    "import config\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For GCN-LSTM model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Model, initializers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tqdm.keras import TqdmCallback\n",
    "import stellargraph as sg\n",
    "from stellargraph.layer import GCN_LSTM\n",
    "\n",
    "# For hyperopt (parameter optimization)\n",
    "from hyperopt import Trials, STATUS_OK, tpe, fmin, hp\n",
    "from hyperopt.pyll.base import scope  # quniform returns float, some parameters require int; use this to force int\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "451c07ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "287a1346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_scale_data(data, seq_len=1):\n",
    "    X_total = data.values\n",
    "\n",
    "    X_total = X_total[(53-seq_len):, :]\n",
    "    scaler, X_total_scaled = utils.scale(X_total)\n",
    "    data = X_total_scaled.T\n",
    "    \n",
    "    X, y = utils.sequence_data_preparation(seq_len, 1, data)\n",
    "    y = y[:, 1].reshape((-1, 1))\n",
    "    features = 13\n",
    "    obs = seq_len*features\n",
    "\n",
    "    trainX = X[:140, :, :]\n",
    "    trainY = y[:140, :]\n",
    "    validX1 = X[140:144, :, :]\n",
    "    validY1 = y[140:144, :]\n",
    "    validX2 = X[144:148, :, :]\n",
    "    validY2 = y[144:148, :]\n",
    "    testX = X[148:, :, :]\n",
    "    testY = y[148:, :]\n",
    "    \n",
    "    print(trainX.shape, validX1.shape, validX2.shape, testX.shape)\n",
    "    print(trainY.shape, validY1.shape, validY2.shape, testY.shape)\n",
    "    \n",
    "    y_scaler, y2 = utils.scale(X_total[:, 1].reshape((len(X_total), 1)))\n",
    "    y2 = X_total[:, -features:]\n",
    "    print(y2.shape)\n",
    "    \n",
    "    return trainX, trainY, validX1, validY1, validX2, validY2, testX, testY, scaler, y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f461a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    def f_nn(params):\n",
    "        # Generate data with given window\n",
    "        saltlake_week = pd.read_csv('../saltlake_week.csv')\n",
    "        data = saltlake_week[['Cases', 'VMT (Veh-Miles)', 'News Sentiment', 'Unemployment Rate', 'PRCP', 'SNWD',\n",
    "                              'Percent_Fully_Vaccinated_5&Older', 'TAVG',\n",
    "                              'Stay at Home', 'Mask', 'School Opening', 'Health Emergency', 'Holiday']]\n",
    "        trainX, trainY, validX1, validY1, validX2, validY2, testX, testY, scaler, y_scaler = format_scale_data(data=data, \n",
    "                                                                                                               seq_len=params['weeks'])\n",
    "        \n",
    "        gc_layers = [params['gcn_units_1'], params['gcn_units_2']]\n",
    "        gc_act = ['relu' for i in range(2)]\n",
    "        lstm_layers = [params['lstm_units_1'], params['lstm_units_2'], params['lstm_units_3'], params['lstm_units_4'],\n",
    "                       params['lstm_units_5'], params['lstm_units_6']]\n",
    "        lstm_act = ['relu' for i in range(6)]\n",
    "        \n",
    "        # GCN-LSTM model\n",
    "        model = GCN_LSTM(\n",
    "                seq_len=params['weeks'],\n",
    "                adj=config.TOTAL_ADJACENT_MATRIX,\n",
    "                gc_layer_sizes=gc_layers,\n",
    "                gc_activations=gc_act,\n",
    "                lstm_layer_sizes=lstm_layers,\n",
    "                lstm_activations=lstm_act,\n",
    "                dropout = params['dropout'],\n",
    "                kernel_initializer=initializers.Identity(gain=1)\n",
    "        )\n",
    "\n",
    "        x_input, x_output = model.in_out_tensors()\n",
    "        model = Model(inputs=x_input, outputs=x_output)\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=params['learning_rate']), loss=\"mse\",\n",
    "              metrics=[\"mse\"])\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, restore_best_weights=True)\n",
    "\n",
    "        result = model.fit(trainX, trainY, verbose=0, validation_data=(validX1, validY1),\n",
    "                            batch_size=4,\n",
    "                            epochs=50,\n",
    "                            callbacks=[TqdmCallback(verbose=1)]\n",
    "                            )\n",
    "\n",
    "        # get the lowest validation loss of the training epochs\n",
    "        validation_loss = np.amin(result.history['val_loss'])\n",
    "        print('Best validation loss of epoch:', validation_loss)\n",
    "\n",
    "\n",
    "        return {'loss': validation_loss, 'status': STATUS_OK, 'model': model, 'params': params}\n",
    "\n",
    "    # hyperparameters to search over with hyperopt\n",
    "    space = {'gcn_units_1': scope.int(hp.quniform('gcn_units_1', 4, 32, 2)),\n",
    "             'gcn_units_2': scope.int(hp.quniform('gcn_units_2', 4, 32, 2)),\n",
    "             'lstm_units_1': scope.int(hp.quniform('lstm_units_1', 8, 128, 4)),\n",
    "             'lstm_units_2': scope.int(hp.quniform('lstm_units_2', 8, 128, 4)),\n",
    "             'lstm_units_3': scope.int(hp.quniform('lstm_units_3', 8, 128, 4)),\n",
    "             'lstm_units_4': scope.int(hp.quniform('lstm_units_4', 8, 128, 4)),\n",
    "             'lstm_units_5': scope.int(hp.quniform('lstm_units_5', 8, 128, 4)),\n",
    "             'lstm_units_6': scope.int(hp.quniform('lstm_units_6', 8, 128, 4)),\n",
    "             'weeks': scope.int(hp.quniform('weeks', 1, 10, 1)), \n",
    "             'learning_rate': hp.uniform('learning_rate', 0.001, 0.1),\n",
    "             'dropout': hp.uniform('dropout', 0.01, 0.5)\n",
    "             }\n",
    "\n",
    "    trials = Trials()\n",
    "    best = fmin(f_nn, space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "\n",
    "    # get best model\n",
    "    best_model = trials.results[np.argmin([r['loss'] for r in trials.results])]['model']\n",
    "    best_params = trials.results[np.argmin([r['loss'] for r in trials.results])]['params']\n",
    "    \n",
    "    # save best model\n",
    "    print(best_params)\n",
    "    print(best_model.summary())\n",
    "    best_model.save('Model/GCN-LSTM-2_6_new')\n",
    "    \n",
    "    # load data\n",
    "    saltlake_week = pd.read_csv('../saltlake_week.csv')\n",
    "    data = saltlake_week[['Cases', 'VMT (Veh-Miles)', 'News Sentiment', 'Unemployment Rate', 'PRCP', 'SNWD',\n",
    "                          'Percent_Fully_Vaccinated_5&Older', 'TAVG', \n",
    "                          'Stay at Home', 'Mask', 'School Opening', 'Health Emergency', 'Holiday']]\n",
    "    trainX, trainY, validX1, validY1, validX2, validY2, testX, testY, scaler, y_scaler = format_scale_data(data=data, \n",
    "                                                                                                        seq_len=best_params['weeks'])\n",
    "    \n",
    "    # evaluate model on second validation set\n",
    "    best_model.evaluate(validX2, validY2)\n",
    "    \n",
    "    # invert predictions of model\n",
    "    yhat_valid2 = best_model.predict(validX2)[:, 1].reshape((-1, 1))\n",
    "    yhat_valid2_inv = y_scaler.inverse_transform(yhat_valid2)\n",
    "    validY2_inv = y_scaler.inverse_transform(validY2.reshape((-1, 1)))\n",
    "    \n",
    "    print(yhat_valid2.shape)\n",
    "    print(yhat_valid2_inv.shape)\n",
    "    print(validY2_inv.shape)\n",
    "    \n",
    "    yhat_train = best_model.predict(trainX)[:, 1].reshape((-1, 1))\n",
    "    yhat_train_inv = y_scaler.inverse_transform(yhat_train)\n",
    "    trainY_inv = y_scaler.inverse_transform(trainY.reshape((-1, 1)))\n",
    "    \n",
    "    # evaluate model with inverted features\n",
    "    print(\"Mean Squared Error: {}\".format(mean_squared_error(validY2_inv, yhat_valid2_inv)))\n",
    "    print(\"Root Mean Squared Error: {}\".format(mean_squared_error(validY2_inv, yhat_valid2_inv, squared=False)))\n",
    "    print(\"Mean Absolute Percentage Error: {}\".format(mean_absolute_percentage_error(validY2_inv, yhat_valid2_inv)))\n",
    "    \n",
    "    # plot model predictions\n",
    "    plt.figure()\n",
    "    plt.plot(yhat_valid2_inv, label='Predicted')\n",
    "    plt.plot(validY2_inv, label='True')\n",
    "    plt.legend()\n",
    "    plt.title(\"Validation Data 2\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(yhat_train_inv, label='Predicted')\n",
    "    plt.plot(trainY_inv, label='True')\n",
    "    plt.legend()\n",
    "    plt.title(\"Training Data\")\n",
    "    plt.show()\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df93a5bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gcn_lstm_2_6_new = run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
